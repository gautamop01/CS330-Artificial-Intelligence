# Rainforcement Learning 
You will apply the concepts in MDPs and Reinforcement learning in applications like gridworld, pacman etc. (project 3: https://inst.eecs.berkeley.edu/~cs188/fa22/projects/proj3/). All questions listed on the page are compulsory. 
Also at the end of the instructions here in classroom, you will find two additional optional questions for bonus credit.
As in the previous assignments, following the instructions and documentation systematically will help you develop code. 
-  Please include relevant comments in your code to help us understand your ideas/implementations.Files to be submitted:
1. valueIterationAgents.py
2. qlearningAgents.py
3. analysis.py
- Include the group number and the names, roll numbers of the members as comments in the beginning of all files which you are submitting. 
- Remember that all members of the group should contribute well - there will be surprise vivas. 
- You are also expected to be honest - Plagiarism will not be tolerated.
- Over the instructions in the page, explore various settings of the parameters being tuned to better understand how RL algorithms work.- Please ensure that only one person from a group makes the submission.Submission date: Oct 3, 2023 11.59 pm.
Optional Questions (for bonus credits):
------------------------------------------------------------------------------------------
##### Question 7: In Question 6, you built an approximate Q-learning agent by using the features as provided by the SimpleExtractor defined in featureExtractors.py. Take some time to understand the SimpleExtractor class containing the getFeatures function. There is scope for improvement of these features as they do not consider the scaredTimers/larger food pellets. Your task is to improve the Approximate Q-learning agent for Pacman by building your own advanced extractor class/features in featureExtractors.py (you are free to construct any features you like). For this you will need to create a new class for the implementation (similar to how the SimpleExtractor class is written in featureExtractors.py).  See if you can demonstrate cases where your features are clearly making a difference.
Additional file to be submitted for this question: featureExtractors.py
Question 8: In Question 1, you developed an agent that does Value Iteration. Now develop an agent which does Policy Iteration. Compare the speed of policy iteration vs value iteration on gridworld. The implementation details are upto you - it could be in a new file or  in existing files. When you make a submission please provide documentation to locate your code.
Please write to me explicitly if you do manage to submit a solution for either of the bonus questions.
-----------------------------------------------------------------------------------------
